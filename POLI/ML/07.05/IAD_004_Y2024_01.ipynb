{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKM9mrWQHmep"
      },
      "source": [
        "# <font face=\"Verdana\" size=6 color='#6495ED'> IAD-004 AULA 01: REGRESS√ÉO\n",
        "<font face=\"Verdana\" size=3 color='#40E0D0'> Professores Larissa Driemeier e Thiago Martins\n",
        "\n",
        "<center><img src='https://drive.google.com/uc?export=view&id=1J3dF7v9apzpj27oOsrT8aEagtNIYwq7J' width=\"600\"></center>\n",
        "\n",
        "Este notebook introdut√≥rio √© sobre problemas de Regress√£o, baseado na primeira aula [IAD-004](https://alunoweb.net/moodle/pluginfile.php/141625/mod_resource/content/2/ML1_A01_Y2024.pdf), ano 2024."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qt_qqh1_Aceu"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FP8y854RBU0v"
      },
      "source": [
        "A regress√£o linear consiste em tentar explicar o comportamento de uma vari√°vel, dita *dependente*, a partir de uma ou mais vari√°veis, ditas *independentes*, com um modelo linear.\n",
        "\n",
        "Seja $\\mathbf y = \\left\\{y^{(1)}, y^{(2)}, \\ldots, y^{(m)}\\right\\}$ uma amostra do conjunto de vari√°veis dependentes e $\\mathbf X = \\left\\{\\mathbf x^{(1)}, \\mathbf x^{(2)}, \\ldots, \\mathbf x^{(m)}\\right\\}$ as correspondentes vari√°veis independentes da amostra.\n",
        "\n",
        "O modelo linear para o comportamento destas vari√°veis √© dado pela equa√ß√£o:\n",
        "\\begin{equation}\n",
        " y^{(i)} =  w_0 +  w_1 x_1^{(i)} + w_2 x_2^{(i)}+\\cdots + w_n x_n^{(i)} + \\epsilon^{(i)}\n",
        "\\end{equation}\n",
        "onde $ w_0, \\cdots, w_n$ s√£o *par√¢metros* do modelo e $\\epsilon^{(i)$ √© o erro.\n",
        "\n",
        "Na forma matricial tem-se,\n",
        "\\begin{equation}\n",
        "\\mathbf y = \\begin{bmatrix}y_1\\\\\n",
        "y_2\\\\\n",
        "\\vdots\\\\\n",
        "y_m\\end{bmatrix}\n",
        "\\end{equation}\n",
        "um vetor de dimens√£o $m$, onde $m$ √© o n√∫mero de amostras do conjunto de dados, e\n",
        "\\begin{equation}\n",
        "\\mathbf X = \\begin{bmatrix}x_{1,1} & x_{1,2} & \\ldots & x_{1,n} & 1\\\\\n",
        "x_{2,1} & x_{2,2} & \\ldots & x_{2,n} & 1\\\\\n",
        " \\vdots & \\vdots & \\ddots & \\vdots & \\vdots\\\\\n",
        "x_{m,1} & x_{m,2} & \\ldots & x_{m,n} & 1\\end{bmatrix}=\\begin{bmatrix}\\mathbf x^{(1)}\\\\\n",
        "\\mathbf x^{(2)}\\\\\n",
        " \\vdots \\\\\n",
        "\\mathbf x^{(m)}\\end{bmatrix}\n",
        "\\end{equation}\n",
        "uma matriz $m \\times (n+1)$ cujas primeiras $n$ colunas s√£o compostas por uma amostra de cada uma das $n$ vari√°veis independetes e a sua *√∫ltima* coluna √© composta da constante 1.\n",
        "Define-se tamb√©m,\n",
        "\\begin{equation}\n",
        "\\mathbf w = \\begin{bmatrix}w_0\\\\\n",
        "w_1\\\\\n",
        "w_2\\\\\n",
        "\\vdots\\\\\n",
        "w_n\n",
        "\\end{bmatrix}\n",
        "\\end{equation}\n",
        "√© o vetor de $(n+1)$ componentes dos coeficientes de cada uma das vari√°veis independentes. Note que nesta nota√ß√£o o coeficiente $w_0$ √© o *primeiro* coeficiente (h√° nota√ß√µes distintas nas quais ele √© o √∫ltimo).\n",
        "\n",
        "O modelo linear para o comportamento destas vari√°veis √© dado pela equa√ß√£o:\n",
        "\\begin{equation}\n",
        "\\mathbf y =  \\mathbf X \\mathbf w + \\mathbf e\n",
        "\\end{equation}\n",
        "onde o erro rand√¥mico $\\mathbf e$ do conjunto de dados √© a diferen√ßa entre os valores observados e os valores verdadeiros, n√£o observ√°veis.\n",
        "\n",
        " ![](https://drive.google.com/uc?export=view&id=1mRM2uGuHlB46FuiRz6iaeV9O71P9IbIv)\n",
        "\n",
        "Importante comentar que o erro rand√¥mico n√£o √© observ√°vel, pois sua defini√ß√£o depende do conhecimento de $ \\mathbf X \\mathbf w$. Como n√£o conhecemos o erro, fazemos apenas suposi√ß√µes a seu respeito.\n",
        "\n",
        "No problema de regress√£o, estimamos os par√¢metros reais $\\mathbf w$, de forma que :\n",
        "\\begin{equation}\n",
        "\\hat{\\mathbf y} =  \\mathbf X \\hat{\\mathbf w} +  \\newcommand{\\beps}{\\boldsymbol \\epsilon} \\beps\n",
        "\\end{equation}\n",
        "onde $\\hat{\\mathbf y}$ √© uma aproxima√ß√£o das observa√ß√µes $\\mathbf y$. Define-se ainda o res√≠duo $\\epsilon^{(i)}$ como a diferen√ßa entre o valor observado $ y^{(i)}$ e estimado $\\hat y^{(i)}$,\n",
        "\\begin{equation}\n",
        "\\epsilon^{(i)} = y^{(i)}-\\hat y^{(i)} = y^{(i)}-\\left( \\hat w_0 + \\hat w_1 x_1^{(i)} + w_2 x_2^{(i)}+\\cdots +\\hat w_n x_n^{(i)} \\right)\n",
        "\\end{equation}\n",
        "de forma que $\\beps$ √© o vetor de *res√≠duos* de dimens√£o $n+1$. Os res√≠duos podem ser considerados somente estimativas dos erros. No entanto, s√≥ temos acesso aos res√≠duos, ent√£o √© com isso que trabalhamos.\n",
        "\n",
        "Daqui para frente, por brevidade, e cientes de que sempre estamos buscando um conjunto de par√¢metros que  aproxime a fun√ß√£o real, $\\hat w_i = w_i$.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oht4Dlpb5zri"
      },
      "source": [
        "## As suposi√ß√µes de Gauss-Markov\n",
        "\n",
        "Ao usar estimadores n√£o viesados para os modelos de regress√£o, i√©, $ùê∏\\left(\\epsilon^{(ùëñ)}\\right)=0$, garantimos que pelo menos em m√©dia, estimamos o par√¢metro verdadeiro.\n",
        "\n",
        "Ao comparar diferentes estimadores n√£o viesados, √©, ainda, interessante saber qual deles tem a maior precis√£o poss√≠vel.\n",
        "\n",
        "O teorema de Gauss Markov nos diz que se um certo conjunto de suposi√ß√µes for atendido, a estimativa de m√≠nimos quadrados ordin√°rios para coeficientes de regress√£o fornece a mais baixa vari√¢ncia de amostragem dentro da classe dos estimadores lineares n√£o enviesados (BLUE, do ingl√™s Best Linear Unbiased Estimate) poss√≠vel.\n",
        "\n",
        "1. **Linearidade:** $\\newcommand{\\my}{\\mathbf y}\\my=\\newcommand{mX}{\\mathbf{Xw}}\\mX \\newcommand{\\mw}{\\mathbf w} + \\beps$, os par√¢metros que estimamos usando o m√©todo OLS devem ser lineares.\n",
        "2. **Aleatoriedade:** nossos dados devem ter sido amostrados aleatoriamente na popula√ß√£o, por um mecanismo n√£o relacionado a $\\beps$.\n",
        "5. **Exogeneidade:** como dito no item anterior, os regressores $x^{(i)}$ n√£o s√£o correlacionados com o termo de res√≠duo $cov\\left(x^{(i)},\\epsilon^{(i)}\\right)=0, i\\ne j$.\n",
        "3. **Res√≠duos com m√©dia nula:** Essa suposi√ß√£o afirma que a *m√©dia dos res√≠duos* √© $0$ para qualquer valor de $\\mX$, i√©, $ùê∏(\\epsilon^{(i)}|\\mX)=0$. Colocado de outra forma, nenhuma observa√ß√£o das vari√°veis independentes fornece qualquer informa√ß√£o sobre o valor esperado do res√≠duo. A suposi√ß√£o implica que $E(\\my) = \\mX$. Isso √© importante, pois essencialmente diz que acertamos a fun√ß√£o m√©dia.\n",
        "4. **Res√≠duos com covari√¢ncia nula:** Cada termo de res√≠duo √© independentemente distribu√≠do e n√£o correlacionado $cov\\left(\\epsilon^{(ùëñ)},\\epsilon^{(ùëó)}|\\mX\\right)=0, i\\ne j$. A suposi√ß√£o de nenhuma autocorrela√ß√£o quer dizer que: saber algo sobre o res√≠duo para uma observa√ß√£o n√£o nos diz nada sobre o res√≠duo para qualquer outra observa√ß√£o.\n",
        "6. **Homocedasticidade:** a vari√¢ncia de $\\epsilon^{(i)}$ √© constante para qualquer $i$, i√©, $var\\left(\\epsilon^{(ùëñ)}|\\mX\\right)=\\sigma_{\\epsilon}^2,\\forall i$.\n",
        "\n",
        "Ainda, para garantirmos a m√°xima verossimilhan√ßa, assume-se que o res√≠duo tem distribui√ß√£o normal com m√©dia nula e vari√¢ncia $\\sigma_{\\epsilon}^2$,\n",
        "$$\n",
        "\\beps \\approx N\\left[ 0,\\sigma_{\\epsilon}^2 \\mathbf I \\right]\n",
        "$$\n",
        "\n",
        "\n",
        "\n",
        "Mais matem√°tica sobre o Teorema de Gauss Markov pode ser encontrada no [link](https://web.stanford.edu/~mrosenfe/soc_meth_proj3/matrix_OLS_NYU_notes.pdf)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4L5gvnax19s"
      },
      "source": [
        "\n",
        "\n",
        "## 1. Regress√£o Linear Simples\n",
        "\n",
        "A regress√£o linear simples trata de apenas uma vari√°vel independente.\n",
        "\n",
        "Seja $\\mathbf y = \\left\\{y^{(1)}, y^{(2)}, \\ldots, y^{(m)}\\right\\}$ uma amostra do conjunto de vari√°veis independentes e $\\mathbf x = \\left\\{x^{(1)}, x^{(2)}, \\ldots, x^{(m)}\\right\\}$\n",
        "\n",
        "O modelo linear simples para o comportamento destas vari√°veis √© dado pela equa√ß√£o:\n",
        "\n",
        "\\begin{equation}\n",
        "\\hat y^{(i)} = w_0 + w_1 x^{(i)} + \\epsilon^{(i)}\n",
        "\\end{equation}\n",
        "\n",
        "A hip√≥tese do modelo linear √© a de que os res√≠duos s√£o vari√°veis aleat√≥rias *independentes* distribu√≠das de acordo com uma distribui√ß√£o *Gaussiana* de valor esperado *nulo*,\n",
        "$$\n",
        "\\epsilon^{(i)} \\approx N\\left[ 0,\\sigma_{\\epsilon}^2 \\right]\n",
        "$$\n",
        "\n",
        "Isso significa essencialmente que nossos dados t√™m uma rela√ß√£o linear que √© corrompida pelo ru√≠do gaussiano aleat√≥rio que tem m√©dia zero e varia√ß√£o constante.\n",
        "\n",
        "Isso tem a implica√ß√£o de que $y^{(i)}$  √© uma vari√°vel aleat√≥ria gaussiana e podemos calcular sua expectativa e varia√ß√£o:\n",
        "$$\n",
        "E[y^{(i)}] = E[\\mathbf x^{(i)T} \\mathbf w + \\epsilon^{(i)}] = \\mathbf x^{(i)T} \\mathbf w\n",
        "$$\n",
        "\n",
        "$$\n",
        "Var[y^{(i)}] = Var[\\mathbf x^{(i)T} \\mathbf w + \\epsilon^{(i)}] = \\sigma^2\n",
        "$$\n",
        "onde $\\mathbf x^{(i)}=\\left[x^{(i)} \\quad 1\\right]^T$ e $\\mathbf w=\\left[w_1 \\quad w_0\\right]^T$.\n",
        "\n",
        "Isso equivale a supor que as vari√°veis independentes s√£o resultado da reta $y = w_0 + w_1 x $ sobreposta a um ru√≠do Gaussiano.\n",
        "\n",
        "Adicionando-se a hip√≥tese de que os ru√≠dos Gaussianos s√£o todos com a mesma covari√¢ncia, os par√¢metros da reta de *m√°xima verissimilhan√ßa* s√£o dados pela minimiza√ß√£o da fun√ß√£o custo dada pelo somat√≥rio quadr√°tico dos res√≠duos, i√©:\n",
        "\n",
        "\\begin{equation}\n",
        "\\underset{w_0, w_1}{\\mbox{arg min}} \\sum_i \\left[\\epsilon^{(i)}\\right]^2= \\sum_i \\left(y^{(i)} - w_0 - w_1 x^{(i)}\\right)^2\n",
        "\\end{equation}\n",
        "\n",
        "Ent√£o:\n",
        "\\begin{align}\n",
        "\\frac{\\partial EQT}{\\partial w_0} &= 2  \\sum_i \\left(y^{(i)} - w_0 - w_1 x^{(i)}\\right)(-1)=0\\\\\n",
        "\\frac{\\partial EQT}{\\partial w_1} &= 2  \\sum_i \\left(y^{(i)} - w_0 - w_1 x^{(i)}\\right)(-x^{(i)})=0\n",
        "\\end{align}\n",
        "\n",
        "Portanto, ap√≥s longa, e trivial, manipula√ß√£o alg√©brica,\n",
        "\\begin{align}\n",
        "w_1 &= \\frac{s_{xy}}{s_{xx}}\\\\\n",
        "w_0 &= \\bar{y} - w_1 \\bar{x}\n",
        "\\end{align}\n",
        "definindo-se,\n",
        "\\begin{align}\n",
        "\\bar{x} &= \\frac{1}{n}\\sum_i x^{(i)} \\\\\n",
        "\\bar{y} &= \\frac{1}{n}\\sum_i y^{(i)} \\\\\n",
        "s_{xx} &= \\sum_i (x^{(i)} - \\bar{x})^2 \\\\\n",
        "s_{yy} &= \\sum_i (y^{(i)} - \\bar{y})^2 \\\\\n",
        "s_{xy} &= \\sum_i (x^{(i)} - \\bar{x})(y^{(i)} - \\bar{y})\n",
        "\\end{align}\n",
        "\n",
        "E finalmente, a soma total dos quadrados dos res√≠duos √© dada por:\n",
        "\n",
        "\\begin{equation}\n",
        "R^2 = \\sum_i \\left[\\epsilon^{(i)}\\right]^2=s_{yy}\\left(1-\\frac{s_{xy}^2}{s_{xx} s_{yy}}\\right)\n",
        "\\end{equation}\n",
        "\n",
        "O valor\n",
        "\n",
        "\\begin{equation}\n",
        "r = \\frac{s_{xy}}{\\sqrt{s_{xx} s_{yy}}}\n",
        "\\end{equation}\n",
        "\n",
        "√© chamado de *coeficiente de correla√ß√£o de Pearson*. Este √© um valor que varia de $-1$ a $1$ e mede o qu√£o bem a vari√°vel dependente pode ser explicada por um modelo linear da vari√°vel dependente.\n",
        "\n",
        "Valores mais pr√≥ximos de zero significam um modelo linear menos explicativo.\n",
        "\n",
        "Valores mais pr√≥ximos de $1$ ou $-1$ significam um modelo linear mais explicativo.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_t6Ql3iLZ-Yu"
      },
      "source": [
        "### Exemplo 01\n",
        "\n",
        "Dados de idade e press√£o,\n",
        "```\n",
        "idade = x = [52,59,67,73,64,74,54,61,65,46,72]\n",
        "pressao = y = [132,143,153,162,154,168,137,149,159,128,166]\n",
        "```\n",
        "\n",
        "Determine:\n",
        "1. Os valores de $\\bar{x}$, $\\bar{y}$;\n",
        "2. Os valores de $s_{xx}, s_{yy}, s_{xy}$;\n",
        "3. Os valores de  $w_0$ e $w_1$ no modelo $\\hat y^{(i)} = w_0 + w_1 x^{(i)} + \\epsilon^{(i)}$ de m√°xima verissimilhan√ßa;\n",
        "4. Repita a plotagem *scatter* do enunciado sobreposta √† reta $\\hat y=w_0 + w_1 x$;\n",
        "5. Calcule o res√≠duo quadr√°tico total $\\sum_i \\left[\\epsilon^{(i)}\\right]^2$;\n",
        "6. Calcule o coeficiente de correla√ß√£o de Pearson e compare o valor $s_{yy}(1-r^2)$ com o obtido no item anterior."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "LIw03lm3YMBr"
      },
      "outputs": [],
      "source": [
        "idade =     [ 52, 59, 67, 73, 64, 74, 54, 61, 65, 46, 72]\n",
        "pressao =   [132,143,153,162,154,168,137,149,159,128,166]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "HHpBJsC0aGOw"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "A m√©dia de x √©:  62.45\n",
            "A m√©dia de y √©: 150.09\n"
          ]
        }
      ],
      "source": [
        "x_bar = np.mean(idade)\n",
        "y_bar = np.mean(pressao)\n",
        "print('A m√©dia de x √©: {:6.2f}'.format(x_bar))\n",
        "print('A m√©dia de y √©: {:6.2f}'.format(y_bar))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "2NN8Ge71aWBS"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sxx: 830.7272727272727\n",
            "syy: 1856.909090909091\n",
            "sxy: 1215.5454545454545\n"
          ]
        }
      ],
      "source": [
        "dx = (idade - x_bar)\n",
        "dy = (pressao - y_bar)\n",
        "sxx = np.sum(dx**2)\n",
        "syy = np.sum(dy**2)\n",
        "sxy = np.sum(dx*dy)\n",
        "print('sxx: '+str(sxx))\n",
        "print('syy: '+str(syy))\n",
        "print('sxy: '+str(sxy))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "241axWDzbSBZ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "w0: 58.70551543007224 w1: 1.4632304661851607\n"
          ]
        }
      ],
      "source": [
        "w1_teo=sxy/sxx\n",
        "w0_teo= y_bar-x_bar*w1_teo\n",
        "print('w0: '+str(w0_teo),'w1: '+str(w1_teo))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "X7i2lRvMb9dF"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.scatter(x=idade, y=pressao,alpha=0.75)\n",
        "plt.plot(idade,w0_teo+np.asarray(idade)*w1_teo,color='crimson')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FCdydRLWllSZ",
        "outputId": "0d6b41cc-e1a8-4a7d-fe1c-4d1d1dd31e06"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "w0: 58.19648423796317\n",
            "w1: 1.4712261243031135\n"
          ]
        }
      ],
      "source": [
        "w=[]\n",
        "w0,w1= 0.0,0.5\n",
        "w.append([w0,w1])\n",
        "\n",
        "alpha = 0.0005\n",
        "eps = 1e-4\n",
        "max_iter = 500000\n",
        "\n",
        "m = len(idade)\n",
        "grad_w0 = 0.0\n",
        "grad_w1 = 0.0\n",
        "for i,j in zip(idade,pressao):\n",
        "    grad_w0 += (w0 + w1*i - j)/m\n",
        "    grad_w1 += (w0 + w1*i - j)*i/m\n",
        "grad = [grad_w0,grad_w1]\n",
        "\n",
        "count = 0\n",
        "while np.linalg.norm(grad)>eps and count<max_iter:\n",
        "  grad_w0 = 0.0\n",
        "  grad_w1 = 0.0\n",
        "  for i,j in zip(idade,pressao):\n",
        "    grad_w0 += (w0 + w1*i - j)/m\n",
        "    grad_w1 += (w0 + w1*i - j)*i/m\n",
        "  w0 = w0-alpha*grad_w0\n",
        "  w1 = w1-alpha*grad_w1\n",
        "  w.append([w0,w1])\n",
        "  grad = [grad_w0,grad_w1]\n",
        "  count += 1\n",
        "\n",
        "print('w0: '+str(w0))\n",
        "print('w1: '+str(w1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "qXu4U9T7rCFA"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.scatter(x=idade, y=pressao,alpha=0.75)\n",
        "\n",
        "plt.plot(idade,w0+np.asarray(idade)*w1,color='crimson', label = \"gradiente\")\n",
        "plt.plot(idade,w0_teo+np.asarray(idade)*w1_teo,color='mediumvioletred', label = \"teoria\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "08u8eyM3Eds9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "eps: 78.2859\n",
            "r: 0.9787  syy(1-r2):  78.2859  \n"
          ]
        }
      ],
      "source": [
        "eps = syy*(1.0-sxy**2/(sxx*syy))\n",
        "print('eps: {:2.4f}'.format(eps))\n",
        "r= sxy/(np.sqrt(sxx*syy))\n",
        "print('r: {:2.4f}  syy(1-r2):  {:6.4f}  '.format(r,(syy*(1-r**2))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQelXiw0RWx4"
      },
      "source": [
        "Defini√ß√£o de $R^2$\n",
        "\n",
        "$ùëÖ^2$  (R-quadrado) √© uma medida estat√≠stica de qu√£o pr√≥ximos os dados est√£o da linha de regress√£o ajustada. Tamb√©m √© conhecido como coeficiente de determina√ß√£o.\n",
        "\n",
        "Pode-se calcular a partir de sua defini√ß√£o:\n",
        "$$\n",
        "\\begin{align} R^2&=1-\\frac{\\text{SSR}}{\\text{SST}},\\\\ &=1-\\frac{\\sum({y_i}-\\hat{y_i})^2}{\\sum(y_i-\\bar{y})^2} = \\frac{s_{xy}^2}{s_{xx}s_{yy}} \\end{align}\n",
        "$$\n",
        " onde SSR (sum squared regression) √© a soma do quadrado dos erros da regress√£o, enquanto SST (total sum of squares)  √© a soma do quadrado dos erros, quando a regress√£o coincide com a linha m√©dia ${\\bar y}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "riC9bT9LQjSl"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'sklearn'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m r2_score\n\u001b[1;32m      3\u001b[0m coef \u001b[38;5;241m=\u001b[39m r2_score(np\u001b[38;5;241m.\u001b[39marray(pressao), w0\u001b[38;5;241m+\u001b[39mw1\u001b[38;5;241m*\u001b[39mnp\u001b[38;5;241m.\u001b[39marray(idade))\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(coef)\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import r2_score\n",
        "\n",
        "coef = r2_score(np.array(pressao), w0+w1*np.array(idade))\n",
        "print(coef)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p9bgF7XENDpQ"
      },
      "outputs": [],
      "source": [
        "SSE = (np.array(pressao)-w0-w1*np.array(idade))**2\n",
        "SSy = np.sum((np.array(pressao)-np.mean(pressao))**2)\n",
        "print(1-np.sum(SSE)/SSy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5s6tRKorOhmT"
      },
      "outputs": [],
      "source": [
        "(sxy*sxy/(sxx*syy))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RIcYJKAxF6j-"
      },
      "source": [
        "### Exerc√≠cio 02\n",
        "\n",
        "Os dados abaixo referem-se aos anos de experi√™ncia e sal√°rio de funcion√°rios de uma empresa.\n",
        "\n",
        "Determine a curva de regress√£o e analise a correla√ß√£o entre a curva te√≥rica e os dados disponibilizados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0irA25ww5Ys1"
      },
      "outputs": [],
      "source": [
        "data = np.array([\n",
        "[1.1,39343.00],\n",
        "[1.3,46205.00],\n",
        "[1.5,37731.00],\n",
        "[2.0,43525.00],\n",
        "[2.2,39891.00],\n",
        "[2.9,56642.00],\n",
        "[3.0,60150.00],\n",
        "[3.2,54445.00],\n",
        "[3.2,64445.00],\n",
        "[3.7,57189.00],\n",
        "[3.9,63218.00],\n",
        "[4.0,55794.00],\n",
        "[4.0,56957.00],\n",
        "[4.1,57081.00],\n",
        "[4.5,61111.00],\n",
        "[4.9,67938.00],\n",
        "[5.1,66029.00],\n",
        "[5.3,83088.00],\n",
        "[5.9,81363.00],\n",
        "[6.0,93940.00],\n",
        "[6.8,91738.00],\n",
        "[7.1,98273.00],\n",
        "[7.9,101302.00],\n",
        "[8.2,113812.00],\n",
        "[8.7,109431.00],\n",
        "[9.0,105582.00],\n",
        "[9.5,116969.00],\n",
        "[9.6,112635.00],\n",
        "[10.3,122391.00],[10.5,121872.00]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U9rWIJMV7Oki"
      },
      "outputs": [],
      "source": [
        "w=[]\n",
        "w0,w1= 0.0,0.5\n",
        "w.append([w0,w1])\n",
        "\n",
        "alpha = 0.0005\n",
        "eps = 1e-4\n",
        "max_iter = 500000\n",
        "\n",
        "\n",
        "m = len(idade)\n",
        "grad_w0 = 0.0\n",
        "grad_w1 = 0.0\n",
        "for i,j in zip(idade,pressao):\n",
        "    grad_w0 += (w0 + w1*i - j)/m\n",
        "    grad_w1 += (w0 + w1*i - j)*i/m\n",
        "grad = [grad_w0,grad_w1]\n",
        "\n",
        "x=data[:,0]\n",
        "y=data[:,1]\n",
        "print(x,y)\n",
        "\n",
        "count = 0\n",
        "while np.linalg.norm(grad)>eps and count<max_iter:\n",
        "  grad_w0 = 0.0\n",
        "  grad_w1 = 0.0\n",
        "  for i,j in zip(x,y):\n",
        "    grad_w0 += (w0 + w1*i - j)/m\n",
        "    grad_w1 += (w0 + w1*i - j)*i/m\n",
        "  w0 = w0-alpha*grad_w0\n",
        "  w1 = w1-alpha*grad_w1\n",
        "  w.append([w0,w1])\n",
        "  grad = [grad_w0,grad_w1]\n",
        "  count += 1\n",
        "\n",
        "print('w0: '+str(w0))\n",
        "print('w1: '+str(w1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BKbViORs6Piw"
      },
      "outputs": [],
      "source": [
        "plt.scatter(x=data[:,0], y=data[:,1],alpha=0.75, label = \"Dados\")\n",
        "media = [np.mean(data[:,1])]*len(data)\n",
        "plt.plot(data[:,0], media, color='crimson', label = \"M√©dia\")\n",
        "plt.plot(data[:,0],w0+np.asarray(data[:,0])*w1,color='forestgreen', label = \"Regress√£o\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PUOr8a8rIPeu"
      },
      "outputs": [],
      "source": [
        "data_regr = w0+np.asarray(data[:,0])*w1\n",
        "\n",
        "x_bar = np.mean(data[:,0])\n",
        "y_bar = np.mean(data[:,1])\n",
        "\n",
        "dx = (data[:,0] - x_bar)\n",
        "dy = (data[:,1] - y_bar)\n",
        "dy_regr = (data[:,1] - data_regr)\n",
        "\n",
        "\n",
        "sxx = np.sum(dx**2)\n",
        "syy = np.sum(dy**2)\n",
        "sxy = np.sum(dx*dy)\n",
        "s_regr = np.sum(dy_regr**2)\n",
        "r2= (sxy/(np.sqrt(sxx*syy)))**2\n",
        "r2_regr = (syy - s_regr) / syy\n",
        "\n",
        "\n",
        "print('R2 √©: {:6.2f}'.format(r2))\n",
        "print('R2 √©: {:6.2f}'.format(r2_regr))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1Gv9pKVM9kT"
      },
      "source": [
        "## 2. Regress√£o multilinear\n",
        "\n",
        "A regress√£o multi-linear trata da rela√ß√£o de uma vari√°vel dependente com *m√∫ltiplas* vari√°veis independentes.\n",
        "\n",
        "\\begin{equation}\n",
        "y^{(i)} = w_1 x_1^{(i)} + w_2 x_2^{(i)} + \\dots + w_n x_n^{(i)} +w_0+\\epsilon^{(i)}\n",
        "\\end{equation}\n",
        "\n",
        "A fun√ß√£o perda ou custo √© definida pelo somat√≥rio da fun√ß√£o erro de cada amostra,\n",
        "$$\n",
        "J(\\mathbf{X,w})=\\frac{1}{m} \\sum_{i=1}^n \\textbf{L}\\left(y^{(i)}, h_\\mathbf w(\\mathbf x^{(i)})\\right)\n",
        "$$\n",
        "\n",
        "Utilizando-se a fun√ß√£o erro quadr√°tica tem-se que,\n",
        "$$\n",
        "\\textbf{L}\\left(y^{(i)}, h_\\mathbf w(\\mathbf x^{(i)})\\right) = \\| \\mathbf{y} - \\mathbf{X w} \\|^2_2\n",
        "$$\n",
        "\n",
        "Seguindo a mesma hip√≥tese de que os res√≠duos s√£o vari√°veis aleat√≥rias *independentes* distribu√≠das de acordo com uma distribui√ß√£o *Gaussiana* de valor esperado *nulo*, o vetor $\\mathbf w$ de *m√°xima verossimilhan√ßa* √© dado pela minimiza√ß√£o da fun√ß√£o custo, i√©,:\n",
        "\\begin{equation}\n",
        "\\underset{\\mathbf w}{\\mbox{arg min}} \\parallel \\mathbf \\beps \\parallel^2= \\parallel \\mathbf{y} - \\mathbf{X w} \\parallel^2_2\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0G8LUzAQryt"
      },
      "source": [
        "Suponha que estamos interessados em minimizar, para $\\newcommand{\\bhat}{{\\mathbf w}}\\bhat \\in \\newcommand{\\reals}{\\mathbb{R}} \\reals^n$ qualquer,\n",
        "$$\n",
        "\\newcommand{\\err}{\\mathcal{E}}\n",
        "\\err = \\| \\beps \\|^2 = (\\newcommand{\\my}{\\mathbf y}\\my - \\newcommand{\\mX}{\\mathbf X}\\mX \\bhat)^T (\\my - \\mX \\bhat),\n",
        "$$\n",
        "onde $\\mw \\in \\reals^n$ s√£o os coeficientes da regress√£o. Assume-se, por simplicidade, que $n \\leq m$ e $\\mathrm{rank}(\\mX) = n$.\n",
        "\\begin{align}\n",
        "\\err &= \\my^T\\my-\\bhat^T\\mX^T\\my-\\my^T\\mX\\bhat+\\bhat^T\\mX^T\\mX\\bhat\\\\\n",
        "&=\\my^T\\my-2\\bhat^T\\mX^T\\my+\\bhat^T\\mX^T\\mX\\bhat \\tag{1}\n",
        "\\end{align}\n",
        "onde este desenvolvimento usa o fato de que a transposi√ß√£o de um escalar √© o escalar, ou seja $\\bhat^T\\mX^T\\my=\\my^T\\mX\\bhat$.\n",
        "\n",
        "Para encontrar o $\\bhat$ que minimiza a soma dos res√≠duos quadrados, precisamos tirar a derivada de (1) em rela√ß√£o a $\\bhat$. Isso nos d√° a seguinte equa√ß√£o:\n",
        "\\begin{equation}\n",
        "\\frac{\\partial\\err}{\\partial \\bhat} = -2\\mX^T\\my+ 2 \\mX^T\\mX\\bhat = 0\n",
        "\\end{equation}\n",
        "\n",
        "Da equa√ß√£o acima obtemos o que chamamos de *equa√ß√µes normais*,\n",
        "\\begin{equation}\n",
        "\\mX^T\\mX\\bhat = \\mX^T\\my \\tag{2}\n",
        "\\end{equation}\n",
        "onde, obviamente, $\\mX^T\\mX$ √© sempre quadrada sim√©trica.\n",
        "\n",
        "Lembre-se de que $\\mX^T\\mX$ e $\\mX^T\\my$ s√£o conhecidos de nossos dados, mas $\\bhat$ √© desconhecido. Se o inverso de $\\mX^T\\mX$ existe\n",
        "(ou seja, $\\left(\\mX^T\\mX\\right)^{-1}$, ent√£o a pr√©-multiplica√ß√£o de ambos os lados por esse inverso nos d√° a seguinte equa√ß√£o:\n",
        "\\begin{align}\n",
        "\\left(\\mX^T\\mX\\right)^{-1}\\left(\\mX^T\\mX\\right)\\bhat &= \\left(\\mX^T\\mX\\right)^{-1}\\mX^T\\my \\\\\n",
        "\\bhat &= \\left(\\mX^T\\mX\\right)^{-1}\\mX^T\\my\n",
        "\\end{align}\n",
        "\n",
        "Portanto, $\\err$ √© minimizado quando $\\bhat = (\\mX^T \\mX)^{-1} \\mX^T \\my$ e a matriz $\\left(\\mX^T \\mX\\right)^{-1}\\mX^T$ √© dita a *pseudo-inversa* de $\\mX$.\n",
        "\n",
        "**Nota**: Em geral n√£o √© eficiente calcular explicitamente esta matriz.\n",
        "\n",
        "Por√©m, lembre-se que definimos um res√≠duo, i√©, um erro da previs√£o em rela√ß√£o √† resposta exata $\\beps$,\n",
        "$$\n",
        "\\my=\\mX\\bhat+ \\beps\n",
        "$$\n",
        "\n",
        "Substituindo-se em (2),\n",
        "\\begin{align}\n",
        "\\left(\\mX^T\\mX\\right)\\bhat &= \\mX^T\\left(\\mX\\bhat+ \\beps\\right)\\\\\n",
        "\\left(\\mX^T\\mX\\right)\\bhat &= \\mX^T\\mX\\bhat+ \\mX^T\\beps \\\\\n",
        "\\therefore \\mX^T\\beps = 0\n",
        "\\end{align}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "031JhNnx21dP"
      },
      "source": [
        "### Exemplo 03\n",
        "\n",
        "Dadas as caracter√≠sticas ($x_1$ e $x_2$) e vari√°vel dependente ($y$),\n",
        "```\n",
        "x1 = np.array([4,2,1,3,1,6])\n",
        "x2 = np.array([1,8,0,2,4,7])\n",
        "y = np.array([2,-14,1,-1,-7,-8])\n",
        "```\n",
        "utilize a resposta anal√≠tica,\n",
        "$$\n",
        "\\newcommand{\\mw}{\\mathbf w}\\mw = (\\newcommand{\\mX}{\\mathbf X} \\mX^T \\mX)^{-1} \\mX^T \\newcommand{\\my}{\\mathbf y} \\my\n",
        "$$\n",
        "para encontrar os pesos da regress√£o linear."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mbbLOLP325F4"
      },
      "outputs": [],
      "source": [
        "x1 = np.array([4,2,1,3,1,6])\n",
        "x2 = np.array([1,8,0,2,4,7])\n",
        "y = np.array([2,-14,1,-1,-7,-8])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QGavoTL-3VXc"
      },
      "outputs": [],
      "source": [
        "MX = np.array([np.ones(len(x1)),x1,x2]).T\n",
        "W = np.linalg.solve(MX.T.dot(MX),MX.T.dot(y))\n",
        "print('w0 = '+str(W[0]) + '  w1 = '+str(W[1]) + '  w2 = '+str(W[2]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6O1XA-g6f_RX"
      },
      "source": [
        "__Agora, monte um procedimento iterativo para encontrar os pesos da regress√£o.__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HaCtbhDaYxfR"
      },
      "outputs": [],
      "source": [
        "## Sua resposta##"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26aKmaVeX1S0"
      },
      "source": [
        "Agora veja o exemplo abaixo...\n",
        "\n",
        "A rela√ß√£o entre semanas de trabalho e carros vendidos da *Locadora Jack*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2gHnoE36WfJk"
      },
      "outputs": [],
      "source": [
        "SemanasTrabalho = np.array([168.,428.,296.,392.,80.,56.,352.,444.,168.,200.,4.,52.,20.,228.,72.])\n",
        "CarrosVendidos =  np.array([272.,300.,311.,365.,167.,149.,366.,310.,192.,229.,88.,118.,62.,319.,193.])\n",
        "data = []\n",
        "for i,j in zip(SemanasTrabalho,CarrosVendidos):\n",
        "  data.append([i,j])\n",
        "data = np.array(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MjIvMlzYX8Ie"
      },
      "outputs": [],
      "source": [
        "w=[]\n",
        "w0,w1= 0.,100.\n",
        "w.append([w0,w1])\n",
        "\n",
        "alpha = 0.000025\n",
        "eps = 1e-4\n",
        "max_iter = 500000\n",
        "\n",
        "x=data[:,0]\n",
        "y=data[:,1]\n",
        "\n",
        "m = len(x)\n",
        "grad_w0 = 0.0\n",
        "grad_w1 = 0.0\n",
        "for i,j in zip(x,y):\n",
        "    grad_w0 += (w0 + w1*i - j)/m\n",
        "    grad_w1 += (w0 + w1*i - j)*i/m\n",
        "grad = [grad_w0,grad_w1]\n",
        "\n",
        "count = 0\n",
        "while np.linalg.norm(grad)>eps and count<max_iter:\n",
        "  grad_w0 = 0.0\n",
        "  grad_w1 = 0.0\n",
        "  for i,j in zip(x,y):\n",
        "    grad_w0 += (w0 + w1*i - j)/m\n",
        "    grad_w1 += (w0 + w1*i - j)*i/m\n",
        "  w0 = w0-alpha*grad_w0\n",
        "  w1 = w1-alpha*grad_w1\n",
        "  w.append([w0,w1])\n",
        "  grad = [grad_w0,grad_w1]\n",
        "  count += 1\n",
        "\n",
        "print('w0: '+str(w0))\n",
        "print('w1: '+str(w1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h6zt6SQ-W_PY"
      },
      "outputs": [],
      "source": [
        "plt.scatter(x=SemanasTrabalho, y=CarrosVendidos,alpha=0.75, label = \"Dados\")\n",
        "media = [np.mean(data[:,1])]*len(data)\n",
        "#\n",
        "plt.plot(data[:,0],w0+np.asarray(data[:,0])*w1,color='forestgreen', label = \"Regress√£o\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IiMrRcaMUvfK"
      },
      "outputs": [],
      "source": [
        "data_regr = w0+np.asarray(data[:,0])*w1\n",
        "\n",
        "x_bar = np.mean(data[:,0])\n",
        "y_bar = np.mean(data[:,1])\n",
        "\n",
        "dx = (data[:,0] - x_bar)\n",
        "dy = (data[:,1] - y_bar)\n",
        "dy_regr = (data[:,1] - data_regr)\n",
        "\n",
        "\n",
        "sxx = np.sum(dx**2)\n",
        "syy = np.sum(dy**2)\n",
        "sxy = np.sum(dx*dy)\n",
        "s_regr = np.sum(dy_regr**2)\n",
        "r2= (sxy/(np.sqrt(sxx*syy)))**2\n",
        "r2_regr = (syy - s_regr) / syy\n",
        "\n",
        "\n",
        "print('R2 √©: {:6.2f}'.format(r2))\n",
        "print('R2 √©: {:6.2f}'.format(r2_regr))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ym9lDTOaVHNk"
      },
      "outputs": [],
      "source": [
        "plt.scatter(x=SemanasTrabalho, y=dy_regr,alpha=0.75)\n",
        "media = [np.mean(data[:,1])]*len(data)\n",
        "plt.xlabel(\"Semanas de Trabalho\")\n",
        "plt.ylabel(\"Res√≠duo\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eSwv4yj9YbU8"
      },
      "outputs": [],
      "source": [
        "w0,w1,w2 = 63.851, 1.4095, -0.0019\n",
        "data_regr=w2*np.asarray(data[:,0])**2+w1*np.asarray(data[:,0])+w0\n",
        "regr = []\n",
        "for i,j in zip(SemanasTrabalho,data_regr):\n",
        "  regr.append([i,j])\n",
        "regr = np.array(regr)\n",
        "matrix = regr[np.argsort(regr[:,0])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FkrsWTtuYpLn"
      },
      "outputs": [],
      "source": [
        "plt.scatter(x=SemanasTrabalho, y=y,alpha=0.75, label = \"Dados\")\n",
        "plt.plot(matrix[:,0],matrix[:,1], color='forestgreen', label = \"Regress√£o\")\n",
        "plt.xlabel(\"Semanas de Trabalho\")\n",
        "plt.ylabel(\"Res√≠duo\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d4SeNoWcb77m"
      },
      "outputs": [],
      "source": [
        "x_bar = np.mean(data[:,0])\n",
        "y_bar = np.mean(data[:,1])\n",
        "\n",
        "dx = (data[:,0] - x_bar)\n",
        "dy = (data[:,1] - y_bar)\n",
        "dy_regr = (data[:,1] - data_regr)\n",
        "sxx = np.sum(dx**2)\n",
        "syy = np.sum(dy**2)\n",
        "s_regr = np.sum(dy_regr**2)\n",
        "\n",
        "r2 = (syy - s_regr) / syy\n",
        "print('R2 √©: {:6.2f}'.format(r2_regr))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yHQrtHPjf8zu"
      },
      "outputs": [],
      "source": [
        "plt.scatter(x=SemanasTrabalho, y=dy_regr,alpha=0.75)\n",
        "media = [np.mean(data[:,1])]*len(data)\n",
        "plt.xlabel(\"Semanas de Trabalho\")\n",
        "plt.ylabel(\"Res√≠duo\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-x3LPYWEq2t"
      },
      "source": [
        "## Regress√£o Polinomial\n",
        "\n",
        "Dado $m$ conjuntos de $n$ dados dispostos na matriz $\\mathbf{X} \\in {\\mathbb{R}}^{m\\times n+1}$ rotulados por $\\mathbf{y} \\in {\\mathbb{R}}^m$ j√° definimos anteriormente que o erro ser√° minimizado quando\n",
        "$$\n",
        "\\newcommand{\\mw}{\\mathbf w}\\mw = (\\newcommand{\\mX}{\\mathbf X} \\mX^T \\mX)^{-1} \\mX^T \\newcommand{\\my}{\\mathbf y} \\my\n",
        "$$\n",
        "\n",
        "Derivar por um vetor pode parecer desconfort√°vel, mas n√£o h√° com o que se preocupar. Lembre-se de que aqui apenas usamos nota√ß√£o de matriz para representar convenientemente um sistema de f√≥rmulas lineares. Portanto, derivamos por cada componente do vetor e depois combinamos as derivadas resultantes em um vetor novamente,\n",
        "$$\n",
        "\\frac{\\partial}{\\partial w_{k}}\\sum_{i=1}^{m}\\left(y^{(i)}-\\sum_{j=0}^{n}x_{ij}w_{j}\\right)^{2}=0\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\sum_{i=1}^{m}2\\left(y^{(i)}-\\sum_{j=1}^{n}x_{ij}w_{j}\\right)\\left(\\frac{\\partial}{\\partial w_{k}}\\left[y^{(i)}-\\sum_{j=1}^{n}x_{ij}w_{j}\\right]\\right)=0\n",
        "$$\n",
        "\n",
        "$$\n",
        "-2\\sum_{i=1}^{m}x_{ik}\\left(y^{(i)}-\\sum_{j=1}^{n}x_{ij}w_{j}\\right)=0 \\tag{1}\n",
        "$$\n",
        "\n",
        "Pode-se reescrever as equa√ß√µes (1) na forma matricial. Por exemplo, para um polin√¥mio de ordem $4$,\n",
        "\\begin{equation}\n",
        "              \\begin{pmatrix}\n",
        "              m \\, \\, \\, \\, \\, \\, \\, & \\sum{x^{(i)}}\\, \\, & \\sum{\\left(x^{(i)}\\right)^2} & \\sum{\\left(x^{(i)}\\right)^3} & \\sum{\\left(x^{(i)}\\right)^4}  \\\\\n",
        "              \\sum{x^{(i)}}\\, \\, & \\sum{\\left(x^{(i)}\\right)^2} & \\sum{\\left(x^{(i)}\\right)^3} & \\sum{\\left(x^{(i)}\\right)^4} & \\sum{\\left(x^{(i)}\\right)^5}  \\\\\n",
        "              \\sum{\\left(x^{(i)}\\right)^2} & \\sum{\\left(x^{(i)}\\right)^3} & \\sum{\\left(x^{(i)}\\right)^4} & \\sum{\\left(x^{(i)}\\right)^5} & \\sum{\\left(x^{(i)}\\right)^6}  \\\\\n",
        "              \\sum{\\left(x^{(i)}\\right)^3} & \\sum{\\left(x^{(i)}\\right)^4} & \\sum{\\left(x^{(i)}\\right)^5} & \\sum{\\left(x^{(i)}\\right)^6} & \\sum{\\left(x^{(i)}\\right)^7}  \\\\\n",
        "              \\sum{\\left(x^{(i)}\\right)^4} & \\sum{\\left(x^{(i)}\\right)^5} & \\sum{\\left(x^{(i)}\\right)^6} & \\sum{\\left(x^{(i)}\\right)^7} & \\sum{\\left(x^{(i)}\\right)^8}  \\\\\n",
        "              \\end{pmatrix}\n",
        "              \\begin{pmatrix}\n",
        "              w_0 \\\\\n",
        "              w_1 \\\\\n",
        "              w_2 \\\\\n",
        "              w_3 \\\\\n",
        "              w_4 \\\\\n",
        "              \\end{pmatrix}\n",
        "              =\\begin{pmatrix}\n",
        "              \\sum{ y^{(i)}} \\\\\n",
        "              \\sum{x^{(i)} y^{(i)}} \\\\\n",
        "              \\sum{\\left(x^{(i)}\\right)^2 y^{(i)}} \\\\\n",
        "              \\sum{\\left(x^{(i)}\\right)^3 y^{(i)}} \\\\\n",
        "              \\sum{\\left(x^{(i)}\\right)^4 y^{(i)}} \\\\\n",
        "              \\end{pmatrix} \\tag{2}\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VcnX0E6GXTwu"
      },
      "outputs": [],
      "source": [
        "w=[]\n",
        "w0,w1= 0.0,0.5\n",
        "w.append([w0,w1])\n",
        "\n",
        "alpha = 0.0005\n",
        "eps = 1e-4\n",
        "max_iter = 500000\n",
        "\n",
        "m = len(idade)\n",
        "grad_w0 = (w0 + w1*i - j)/m\n",
        "grad_w1 = (w0 + w1*i - j)*i/m\n",
        "grad = [grad_w0,grad_w1]\n",
        "\n",
        "x=data[:,0]\n",
        "y=data[:,1]\n",
        "\n",
        "count = 0\n",
        "while np.linalg.norm(grad)>eps and count<max_iter:\n",
        "  grad_w0 = 0.0\n",
        "  grad_w1 = 0.0\n",
        "  for i,j in zip(x,y):\n",
        "    grad_w0 += (w0 + w1*i - j)/m\n",
        "    grad_w1 += (w0 + w1*i - j)*i/m\n",
        "  w0 = w0-alpha*grad_w0\n",
        "  w1 = w1-alpha*grad_w1\n",
        "  w.append([w0,w1])\n",
        "  grad = [grad_w0,grad_w1]\n",
        "  count += 1\n",
        "\n",
        "print('w0: '+str(w0))\n",
        "print('w1: '+str(w1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pA4SqPz0Xmke"
      },
      "outputs": [],
      "source": [
        "plt.scatter(x=idade, y=pressao,alpha=0.75)\n",
        "plt.plot(idade,w0_teo+np.asarray(idade)*w1_teo,color='crimson')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wWuSKujzjdyI"
      },
      "source": [
        "### Exemplo 04\n",
        "\n",
        "Regress√£o polinomial √© principalmente aplic√°vel a estudos onde os ambientes s√£o altamente controlados e as observa√ß√µes s√£o feitas com um n√≠vel especificado de toler√¢ncia.\n",
        "\n",
        "Os dados abaixo s√£o os consumos de eletricidade, em quilowatts-hora por m√™s, de dez casas e suas respectivas √°reas, em metros quadrados,\n",
        "\n",
        "| √Årea | KW Hrs/Mes |\n",
        "| ---  | --- |\n",
        "| 120 | \t1182|\n",
        "| 135 | \t1172|\n",
        "| 147 | \t1264|\n",
        "| 160 | \t1493|\n",
        "| 171 | \t1571|\n",
        "| 184 | \t1711|\n",
        "| 198 | \t1804|\n",
        "| 223 | \t1840|\n",
        "| 240 | \t1956|\n",
        "| 293 | \t1954|\n",
        "\n",
        "Os dados podem ser modelados por meio de um polin√¥mio de segundo grau, com a seguinte equa√ß√£o:\n",
        "\n",
        "\\begin{equation}\n",
        "consumo = w_0 + w_1 area + w_2 area^2\n",
        "\\end{equation}\n",
        "\n",
        "Estime os coeficientes desconhecidos do modelo, $w_0$, $w_1$ e $w_2$, minimizando os desvios entre os dados e o resultado do modelo (ajuste de m√≠nimos quadrados).\n",
        "\n",
        "*Nota*: Use a fun√ß√£o ```np.linalg.solve(a, b)``` para resolver o sistema $ax=b$ da equa√ß√£o (2)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rjUycOvmD_Nw"
      },
      "outputs": [],
      "source": [
        "data = np.array([[1290 , 1182],\n",
        "[1350 , 1172],\n",
        "[1470 , 1264],\n",
        "[1600 , 1493],\n",
        "[1710 , 1571],\n",
        "[1840 , 1711],\n",
        "[1980 , 1804],\n",
        "[2230 , 1840],\n",
        "[2400 , 1956],\n",
        "[2930 , 1954]])\n",
        "\n",
        "area   = data[:,0]\n",
        "consumo = data[:,1]\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(area, consumo, 'bo', color=\"black\")\n",
        "plt.xlabel(r'√Årea ($m^2$)')\n",
        "plt.ylabel(r'Consumo ($KW h/mes$)')\n",
        "plt.title('√Årea vs Consumo')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c26C1JGXQ9Re"
      },
      "outputs": [],
      "source": [
        "aux = np.array([len(area), np.sum(area), np.sum(area**2), np.sum(area**3), np.sum(area**4)])\n",
        "\n",
        "b = np.array([[np.sum(consumo)],[np.sum(consumo*area)],[np.sum(consumo*area**2)]])\n",
        "n=2\n",
        "a=[]\n",
        "for i in range(n+1):\n",
        "  a.append([aux[i],aux[i+1],aux[i+2]])\n",
        "\n",
        "W = np.linalg.solve(a,b)\n",
        "print('w0 = '+str(W[0]) + '  w1 = '+str(W[1]) + '  w2 = '+str(W[2]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPBkrNLjSlCh"
      },
      "source": [
        "Como gabarito vamos usar uma biblioteca a fun√ß√£o `numpy.polyfit(x,y,n)` retorna os coeficientes para um polin√¥mio de grau `n` que melhor se ajusta aos dados. Os coeficientes retornados pela fun√ß√£o est√£o em forma descendente (par√¢metro que acompanha a maior pot√™ncia primeiro) e seu comprimento √© $n+1$.\n",
        "\n",
        "Depois de criar o modelo, vamos verificar se ele realmente se encaixa em nossos dados. Para fazer isso, usaremos o modelo para avaliar o polin√¥mio em tempos espa√ßados uniformemente. Para avaliar o modelo nos pontos especificados, podemos usar a fun√ß√£o `poly1d()`. Essa fun√ß√£o retorna o valor de um polin√¥mio de grau $n$ avaliado nos pontos fornecidos. O argumento de entrada √© um vetor de comprimento $n + 1$ cujos elementos s√£o os coeficientes das pot√™ncias descendentes do polin√¥mio a ser avaliado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0SjUe_K3S8YQ"
      },
      "outputs": [],
      "source": [
        "omegas = np.polyfit(area, consumo,2)\n",
        "y_bar = np.poly1d(omegas)\n",
        "x_bar = np.linspace(1000,3000, 1000)\n",
        "print('w0: '+str(omegas[0]),'w1: '+str(omegas[1]),'w2: '+str(omegas[2]))\n",
        "plt.figure()\n",
        "plt.plot(area, consumo, 'bo', color=\"black\", label='data')\n",
        "plt.xlabel(r'√Årea ($m^2$)')\n",
        "plt.ylabel(r'Consumo ($KW h/mes$)')\n",
        "plt.title('√Årea vs Consumo')\n",
        "plt.plot(x_bar, y_bar(x_bar), '-', color='darkcyan', label='regress√£o')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "joDipy5LnteH"
      },
      "source": [
        "Mude o grau do polin√¥mio para `5` e veja como se comporta sua resposta."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6yb4kMe2nmY7"
      },
      "outputs": [],
      "source": [
        "omegas = np.polyfit(area, consumo,5)\n",
        "y_bar = np.poly1d(omegas)\n",
        "x_bar = np.linspace(1000,3000, 1000)\n",
        "print('w0: '+str(omegas[0]),'w1: '+str(omegas[1]),'w2: '+str(omegas[2]))\n",
        "plt.figure()\n",
        "plt.plot(area, consumo, 'bo', color=\"black\", label='data')\n",
        "plt.xlabel(r'√Årea ($m^2$)')\n",
        "plt.ylabel(r'Consumo ($KW h/mes$)')\n",
        "plt.title('√Årea vs Consumo')\n",
        "plt.plot(x_bar, y_bar(x_bar), '-', color='darkcyan', label='regress√£o')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIWpoc4Y1IDe"
      },
      "source": [
        "## Uma breve introdu√ß√£o a overfitting e underfitting\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mFXpl_ty36xh"
      },
      "source": [
        "### Vari√¢ncia (Variance)\n",
        "\n",
        "A vari√¢ncia √© um erro definido pela alta sensibilidade a pequenas flutua√ß√µes no conjunto de treinamento. Erro devido √† tend√™ncia do algoritmo de modelar o ru√≠do aleat√≥rio nos dados de treinamento, em vez das sa√≠das pretendidas. Esse fen√¥meno √© conhecido como *overfitting*.\n",
        "\n",
        "A vari√¢ncia ser expressa matematicamente como:\n",
        "\n",
        "\\begin{equation}\n",
        "Var[\\mathbf y] = E[(\\mathbf y-E[\\mathbf y])^2] = E[\\mathbf y^2] - E[\\mathbf y]^2 \\tag{2}\n",
        "\\end{equation}\n",
        "\n",
        "A igualdade acima √© essencial ao entendimento da rela√ß√£o entre vi√©s e vari√¢ncia e erro quadr√°tico m√©dio, e √© provada a seguir,\n",
        "\\begin{align}\n",
        "Var[\\mathbf y] =& E[(\\mathbf y- E[\\mathbf y])^2] \\\\\n",
        "=& E[\\mathbf y^2 - 2 \\mathbf y E[\\mathbf y] + E[\\mathbf y]^2] \\\\\n",
        "=& E[\\mathbf y^2] - 2E[\\mathbf y]^2 + E[\\mathbf y]^2 \\\\\n",
        "=& E[\\mathbf y^2] - E[\\mathbf y]^2\n",
        "\\end{align}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zku_fORC3Okq"
      },
      "source": [
        "### Vi√©s (Bias)\n",
        "Vi√©s √© a tend√™ncia de um estimador escolher um modelo para os dados que n√£o s√£o estruturalmente corretos. Um estimador tendencioso √© aquele que faz suposi√ß√µes incorretas no n√≠vel do modelo sobre o conjunto de dados.\n",
        "Para o caso de nossa regress√£o, erro devido √† incapacidade da hip√≥tese $h$ de se encaixar perfeitamente em $y$. Por exemplo, suponha que usamos um modelo de regress√£o linear em uma fun√ß√£o $y$ quadr√°tica ou c√∫bica.\n",
        "\n",
        "Matematicamente,\n",
        "\\begin{equation}\n",
        "\\text{Bias}[\\hat{y}^{(i)}(\\mathbf x^{(i)})] = E[\\hat{y}(\\mathbf x^{(i)}) - y(\\mathbf x^{(i)})] \\tag{1}\n",
        "\\end{equation}\n",
        "\n",
        "Vi√©s tamb√©m √© conhecido como underfitting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_4amqE63TTM"
      },
      "source": [
        "### MSE e sua decomposi√ß√£o em vi√©s e vari√¢ncia\n",
        "Dessa forma, pode-se reescrever a f√≥rmula de $MSE$ como\n",
        "\n",
        "\\begin{align}\n",
        "MSE =& E[(y- \\hat{y})^2] \\\\\n",
        "=& E[y^2 + \\hat{y}^2 - 2 y\\hat{y}] \\\\\n",
        "=& \\text{Var}(y) + E[y]^2 + \\text{Var}[\\hat{y}] + E[\\hat{y}]^2 - 2 y E[\\hat{y}] \\\\\n",
        "=& \\text{Var}(y) + \\text{Var}(\\hat{y}) + E[(y^2 - 2 y E[\\hat{y}] + E[\\hat{y}]^2)] \\\\\n",
        "=& \\text{Var}(y) + \\text{Var}(\\hat{y}) +E[(y - E[\\hat{y}])^2] \\\\\n",
        "=& e^2 + \\text{Var}[\\hat{y}] + \\text{Bias}[\\hat{y}]^2\n",
        "\\end{align}\n",
        "\n",
        "Este resultado mostra que o erro quadr√°tico do estimador √© a soma da vari√¢ncia do estimador (qu√£o mal ele generaliza; seu n√≠vel de overfitting), o vi√©s (qu√£o pobre √© seu ajuste; seu n√≠vel de underfitting) e um erro irredut√≠vel no conjunto de dados subjacente, $e$.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cn6ydJhN4Baa"
      },
      "source": [
        "\n",
        "Um modelo com __ALTO VI√âS__ aprende rela√ß√µes erradas e gera previs√µes longe do esperado. O modelo n√£o aprende corretamente com o conjunto de dados, assumindo informa√ß√µes sobre os dados que n√£o s√£o necessariamente corretas. Dessa forma, modelos com alto vi√©s possuem um problema de underfitting.\n",
        "\n",
        "Modelos com alta __ALTA VARI√ÇNCIA__ focam excessivamente se ajustar aos dados e, inclusive, ao ru√≠do. Assim, esses modelos t√™m um problema de overfitting, ou seja, se adaptam t√£o bem ao conjunto de dados que n√£o conseguem generalizar para al√©m dele.\n",
        "\n",
        "<center><img src='https://drive.google.com/uc?export=view&id=1QIKLgbTJofvRur0RH8V3r2aRLFWqeqaN' width=\"600\"></center>\n",
        "\n",
        "\n",
        "Dado um erro constante, isso significa que sempre haver√° uma troca entre vi√©s e vari√¢ncia. Ter muito vi√©s ou muita varia√ß√£o n√£o √© bom para um modelo, mas por diferentes motivos. Um modelo de alto vi√©s e baixa varia√ß√£o provavelmente acabar√° impreciso nos conjuntos de dados de treinamento e valida√ß√£o, e suas previs√µes provavelmente n√£o se desviar√£o muito com base na amostra de dados em que ele √© treinado. Por outro lado, um modelo de vi√©s baixo e alta vari√¢ncia provavelmente fornecer√° bons resultados em um conjunto de dados de treinamento, mas falhar√° ao tentar generalizar para um conjunto de dados de valida√ß√£o."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8AQOib_4MWh"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfYIkA3W1RSj"
      },
      "source": [
        "### Exemplo 05\n",
        "\n",
        "Com os dados abaixo,\n",
        "```\n",
        "ùë• = [0., 0.18, 0.25, 0.4, 0.45, 0.55, 0.63, 0.75, 0.85, 1.]\n",
        "ùë¶ = [0.3, 0.8, 1., 0.95, 0.25, 0.3, -0.9, -0.7, -0.8, 0.35]\n",
        "```\n",
        "modifique a ordem de aproxima√ß√£o de 0 a 9 e responda:\n",
        "1. o que aconteceu com os valores dos par√¢metros a medida que o grau do polin√¥mio de interpola√ß√£o aumentou?\n",
        "2. porque isso aconteceu?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "4mQk1oyC7rJD"
      },
      "outputs": [],
      "source": [
        "x=np.array([0.,0.18,0.25,0.4,0.45,0.55,0.63,0.75,0.85,1.])\n",
        "y=np.array([0.3,0.8,1.,0.95,0.25,0.3,-0.9,-0.7,-0.8,0.35])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "tx9Q_TC98Hka"
      },
      "outputs": [],
      "source": [
        "import operator\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.metrics import mean_squared_error, r2_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oTU6vDUF7tvf"
      },
      "outputs": [],
      "source": [
        "from sklearn.pipeline import make_pipeline\n",
        "colors = ['SkyBlue','DeepSkyBlue', 'CornflowerBlue', 'DodgerBlue', 'RoyalBlue', 'Blue', 'MediumBlue', 'DarkBlue', 'Navy']\n",
        "for i in range(0,10):\n",
        "  plt.scatter(x, y, color=\"black\", label = 'dataset')\n",
        "  #veja que constru√≠mos uma pipeline, para repetir a sequencia de gerar as features e calcular os par√¢metros da regress√£o\n",
        "  model = make_pipeline(PolynomialFeatures(degree=i), LinearRegression())\n",
        "  model.fit(np.array(x).reshape(-1, 1), y)\n",
        "  x_reg = np.arange(0,1,0.01)\n",
        "  y_reg = model.predict(x_reg.reshape(-1, 1))\n",
        "  plt.plot(x_reg, y_reg, color=colors[i-1], label = 'degree '+str(i))\n",
        "  plt.legend()\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q8q1fm_o7xGM"
      },
      "outputs": [],
      "source": [
        "colors = ['SkyBlue','DeepSkyBlue', 'CornflowerBlue', 'DodgerBlue', 'RoyalBlue', 'Blue', 'MediumBlue', 'DarkBlue', 'Navy']\n",
        "for i in range(0,10):\n",
        "  plt.scatter(x, y, color=\"black\")\n",
        "  polynomial_features= PolynomialFeatures(degree=i)\n",
        "  x_poly = polynomial_features.fit_transform(x.reshape(-1,1))\n",
        "  model = LinearRegression()\n",
        "  model.fit(x_poly, y)\n",
        "  y_poly_pred = model.predict(x_poly)\n",
        "\n",
        "  rmse = np.sqrt(mean_squared_error(y,y_poly_pred))\n",
        "  r2 = r2_score(y,y_poly_pred)\n",
        "  print(\"RMSE:\", rmse)\n",
        "  print(\"R2:\", r2)\n",
        "  print(\"Coeficientes:\", model.coef_)\n",
        "  print(\"Intercepta√ß√£o:\", model.intercept_)\n",
        "  # sort the values of x before line plot\n",
        "  sort_axis = operator.itemgetter(0)\n",
        "  sorted_zip = sorted(zip(x,y_poly_pred), key=sort_axis)\n",
        "  x_sort, y_poly_pred = zip(*sorted_zip)\n",
        "  plt.plot(x_sort, y_poly_pred, color=colors[i-1], label = 'degree '+str(i))\n",
        "  plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
